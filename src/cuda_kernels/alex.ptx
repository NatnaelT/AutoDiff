//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19856038
// Cuda compilation tools, release 7.5, V7.5.17
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_20
.address_size 64

	// .globl	alex

.visible .entry alex(
	.param .u32 alex_param_0,
	.param .u64 alex_param_1,
	.param .u64 alex_param_2
)
{
	.reg .pred 	%p<15>;
	.reg .b32 	%r<56>;
	.reg .f64 	%fd<120>;
	.reg .b64 	%rd<8>;


	ld.param.u32 	%r22, [alex_param_0];
	ld.param.u64 	%rd2, [alex_param_1];
	ld.param.u64 	%rd3, [alex_param_2];
	mov.u32 	%r23, %tid.x;
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	mad.lo.s32 	%r1, %r24, %r25, %r23;
	setp.ge.s32	%p1, %r1, %r22;
	@%p1 bra 	BB0_21;

	cvta.to.global.u64 	%rd4, %rd2;
	mul.wide.s32 	%rd5, %r1, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	setp.gt.f64	%p2, %fd1, 0dBFE0000000000000;
	cvta.to.global.u64 	%rd7, %rd3;
	add.s64 	%rd1, %rd7, %rd5;
	@%p2 bra 	BB0_20;
	bra.uni 	BB0_2;

BB0_20:
	st.global.f64 	[%rd1], %fd1;
	bra.uni 	BB0_21;

BB0_2:
	neg.f64 	%fd2, %fd1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd2;
	}
	setp.lt.s32	%p3, %r48, 2146435072;
	setp.lt.f64	%p4, %fd1, 0d8000000000000000;
	and.pred  	%p5, %p4, %p3;
	@%p5 bra 	BB0_7;
	bra.uni 	BB0_3;

BB0_7:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd2;
	}
	mov.u32 	%r50, -1023;
	setp.gt.s32	%p9, %r48, 1048575;
	@%p9 bra 	BB0_9;

	mul.f64 	%fd18, %fd1, 0dC350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd18;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd18;
	}
	mov.u32 	%r50, -1077;

BB0_9:
	shr.u32 	%r28, %r48, 20;
	add.s32 	%r51, %r50, %r28;
	and.b32  	%r29, %r48, -2146435073;
	or.b32  	%r30, %r29, 1072693248;
	mov.b64 	%fd116, {%r49, %r30};
	setp.lt.s32	%p10, %r30, 1073127583;
	@%p10 bra 	BB0_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r31, %temp}, %fd116;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd116;
	}
	add.s32 	%r33, %r32, -1048576;
	mov.b64 	%fd116, {%r31, %r33};
	add.s32 	%r51, %r51, 1;

BB0_11:
	add.f64 	%fd20, %fd116, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd19,%fd20;
	// inline asm
	neg.f64 	%fd21, %fd20;
	mov.f64 	%fd22, 0d3FF0000000000000;
	fma.rn.f64 	%fd23, %fd21, %fd19, %fd22;
	fma.rn.f64 	%fd24, %fd23, %fd23, %fd23;
	fma.rn.f64 	%fd25, %fd24, %fd19, %fd19;
	add.f64 	%fd26, %fd116, 0dBFF0000000000000;
	mul.f64 	%fd27, %fd26, %fd25;
	fma.rn.f64 	%fd28, %fd26, %fd25, %fd27;
	mul.f64 	%fd29, %fd28, %fd28;
	mov.f64 	%fd30, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd31, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd32, %fd31, %fd29, %fd30;
	mov.f64 	%fd33, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd34, %fd32, %fd29, %fd33;
	mov.f64 	%fd35, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd36, %fd34, %fd29, %fd35;
	mov.f64 	%fd37, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd38, %fd36, %fd29, %fd37;
	mov.f64 	%fd39, 0d3F624924923BE72D;
	fma.rn.f64 	%fd40, %fd38, %fd29, %fd39;
	mov.f64 	%fd41, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd42, %fd40, %fd29, %fd41;
	mov.f64 	%fd43, 0d3FB5555555555554;
	fma.rn.f64 	%fd44, %fd42, %fd29, %fd43;
	sub.f64 	%fd45, %fd26, %fd28;
	add.f64 	%fd46, %fd45, %fd45;
	neg.f64 	%fd47, %fd28;
	fma.rn.f64 	%fd48, %fd47, %fd26, %fd46;
	mul.f64 	%fd49, %fd25, %fd48;
	mul.f64 	%fd50, %fd29, %fd44;
	fma.rn.f64 	%fd51, %fd50, %fd28, %fd49;
	xor.b32  	%r34, %r51, -2147483648;
	mov.u32 	%r35, 1127219200;
	mov.b64 	%fd52, {%r34, %r35};
	mov.u32 	%r36, -2147483648;
	mov.b64 	%fd53, {%r36, %r35};
	sub.f64 	%fd54, %fd52, %fd53;
	mov.f64 	%fd55, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd56, %fd54, %fd55, %fd28;
	neg.f64 	%fd57, %fd54;
	fma.rn.f64 	%fd58, %fd57, %fd55, %fd56;
	sub.f64 	%fd59, %fd58, %fd28;
	sub.f64 	%fd60, %fd51, %fd59;
	mov.f64 	%fd61, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd62, %fd54, %fd61, %fd60;
	add.f64 	%fd117, %fd56, %fd62;
	bra.uni 	BB0_12;

BB0_3:
	abs.f64 	%fd16, %fd2;
	setp.gtu.f64	%p6, %fd16, 0d7FF0000000000000;
	@%p6 bra 	BB0_6;
	bra.uni 	BB0_4;

BB0_6:
	sub.f64 	%fd117, %fd2, %fd1;
	bra.uni 	BB0_12;

BB0_4:
	setp.eq.f64	%p7, %fd1, 0d8000000000000000;
	mov.f64 	%fd117, 0dFFF0000000000000;
	@%p7 bra 	BB0_12;

	setp.eq.f64	%p8, %fd1, 0dFFF0000000000000;
	selp.f64	%fd117, %fd2, 0dFFF8000000000000, %p8;

BB0_12:
	mov.f64 	%fd63, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd63;
	}
	setp.lt.s32	%p11, %r52, 2146435072;
	@%p11 bra 	BB0_14;
	bra.uni 	BB0_13;

BB0_14:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd63;
	}
	mov.u32 	%r54, -1023;
	setp.gt.s32	%p13, %r52, 1048575;
	@%p13 bra 	BB0_16;

	mov.f64 	%fd67, 0d4340000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd67;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd67;
	}
	mov.u32 	%r54, -1077;

BB0_16:
	shr.u32 	%r39, %r52, 20;
	add.s32 	%r55, %r54, %r39;
	and.b32  	%r40, %r52, -2146435073;
	or.b32  	%r41, %r40, 1072693248;
	mov.b64 	%fd118, {%r53, %r41};
	setp.lt.s32	%p14, %r41, 1073127583;
	@%p14 bra 	BB0_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd118;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd118;
	}
	add.s32 	%r44, %r43, -1048576;
	mov.b64 	%fd118, {%r42, %r44};
	add.s32 	%r55, %r55, 1;

BB0_18:
	add.f64 	%fd69, %fd118, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd68,%fd69;
	// inline asm
	neg.f64 	%fd70, %fd69;
	mov.f64 	%fd71, 0d3FF0000000000000;
	fma.rn.f64 	%fd72, %fd70, %fd68, %fd71;
	fma.rn.f64 	%fd73, %fd72, %fd72, %fd72;
	fma.rn.f64 	%fd74, %fd73, %fd68, %fd68;
	add.f64 	%fd75, %fd118, 0dBFF0000000000000;
	mul.f64 	%fd76, %fd75, %fd74;
	fma.rn.f64 	%fd77, %fd75, %fd74, %fd76;
	mul.f64 	%fd78, %fd77, %fd77;
	mov.f64 	%fd79, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd80, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd81, %fd80, %fd78, %fd79;
	mov.f64 	%fd82, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd83, %fd81, %fd78, %fd82;
	mov.f64 	%fd84, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd85, %fd83, %fd78, %fd84;
	mov.f64 	%fd86, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd87, %fd85, %fd78, %fd86;
	mov.f64 	%fd88, 0d3F624924923BE72D;
	fma.rn.f64 	%fd89, %fd87, %fd78, %fd88;
	mov.f64 	%fd90, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd91, %fd89, %fd78, %fd90;
	mov.f64 	%fd92, 0d3FB5555555555554;
	fma.rn.f64 	%fd93, %fd91, %fd78, %fd92;
	sub.f64 	%fd94, %fd75, %fd77;
	add.f64 	%fd95, %fd94, %fd94;
	neg.f64 	%fd96, %fd77;
	fma.rn.f64 	%fd97, %fd96, %fd75, %fd95;
	mul.f64 	%fd98, %fd74, %fd97;
	mul.f64 	%fd99, %fd78, %fd93;
	fma.rn.f64 	%fd100, %fd99, %fd77, %fd98;
	xor.b32  	%r45, %r55, -2147483648;
	mov.u32 	%r46, 1127219200;
	mov.b64 	%fd101, {%r45, %r46};
	mov.u32 	%r47, -2147483648;
	mov.b64 	%fd102, {%r47, %r46};
	sub.f64 	%fd103, %fd101, %fd102;
	mov.f64 	%fd104, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd105, %fd103, %fd104, %fd77;
	neg.f64 	%fd106, %fd103;
	fma.rn.f64 	%fd107, %fd106, %fd104, %fd105;
	sub.f64 	%fd108, %fd107, %fd77;
	sub.f64 	%fd109, %fd100, %fd108;
	mov.f64 	%fd110, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd111, %fd103, %fd110, %fd109;
	add.f64 	%fd119, %fd105, %fd111;
	bra.uni 	BB0_19;

BB0_13:
	abs.f64 	%fd65, %fd63;
	setp.gtu.f64	%p12, %fd65, 0d7FF0000000000000;
	selp.f64	%fd119, 0d3FF0000000000000, 0dFFF8000000000000, %p12;

BB0_19:
	mov.f64 	%fd112, 0d3FF0000000000000;
	sub.f64 	%fd113, %fd112, %fd119;
	mul.f64 	%fd114, %fd113, 0dBFE0000000000000;
	fma.rn.f64 	%fd115, %fd117, 0dBFE0000000000000, %fd114;
	st.global.f64 	[%rd1], %fd115;

BB0_21:
	ret;
}


