//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19856038
// Cuda compilation tools, release 7.5, V7.5.17
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_20
.address_size 64

	// .globl	binaryentropyXsigmoidY_32

.visible .entry binaryentropyXsigmoidY_32(
	.param .u32 binaryentropyXsigmoidY_32_param_0,
	.param .u64 binaryentropyXsigmoidY_32_param_1,
	.param .u64 binaryentropyXsigmoidY_32_param_2,
	.param .u64 binaryentropyXsigmoidY_32_param_3
)
{
	.reg .pred 	%p<18>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<56>;
	.reg .f64 	%fd<123>;
	.reg .b64 	%rd<14>;


	ld.param.u32 	%r22, [binaryentropyXsigmoidY_32_param_0];
	ld.param.u64 	%rd3, [binaryentropyXsigmoidY_32_param_1];
	ld.param.u64 	%rd4, [binaryentropyXsigmoidY_32_param_2];
	ld.param.u64 	%rd5, [binaryentropyXsigmoidY_32_param_3];
	mov.u32 	%r23, %tid.x;
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	mad.lo.s32 	%r1, %r24, %r25, %r23;
	setp.ge.s32	%p1, %r1, %r22;
	@%p1 bra 	BB0_22;

	cvta.to.global.u64 	%rd6, %rd3;
	cvt.s64.s32	%rd1, %r1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.f32 	%f1, [%rd8];
	lg2.approx.ftz.f32 	%f2, %f1;
	cvt.ftz.f64.f32	%fd18, %f1;
	mov.f64 	%fd19, 0d3FF0000000000000;
	sub.f64 	%fd1, %fd19, %fd18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd1;
	}
	setp.gt.f64	%p2, %fd1, 0d0000000000000000;
	setp.lt.s32	%p3, %r48, 2146435072;
	and.pred  	%p4, %p2, %p3;
	@%p4 bra 	BB0_6;
	bra.uni 	BB0_2;

BB0_6:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd1;
	}
	mov.u32 	%r50, -1023;
	setp.gt.s32	%p8, %r48, 1048575;
	@%p8 bra 	BB0_8;

	mul.f64 	%fd22, %fd1, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd22;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd22;
	}
	mov.u32 	%r50, -1077;

BB0_8:
	shr.u32 	%r28, %r48, 20;
	add.s32 	%r51, %r50, %r28;
	and.b32  	%r29, %r48, -2146435073;
	or.b32  	%r30, %r29, 1072693248;
	mov.b64 	%fd119, {%r49, %r30};
	setp.lt.s32	%p9, %r30, 1073127583;
	@%p9 bra 	BB0_10;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r31, %temp}, %fd119;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd119;
	}
	add.s32 	%r33, %r32, -1048576;
	mov.b64 	%fd119, {%r31, %r33};
	add.s32 	%r51, %r51, 1;

BB0_10:
	add.f64 	%fd24, %fd119, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd23,%fd24;
	// inline asm
	neg.f64 	%fd25, %fd24;
	fma.rn.f64 	%fd27, %fd25, %fd23, %fd19;
	fma.rn.f64 	%fd28, %fd27, %fd27, %fd27;
	fma.rn.f64 	%fd29, %fd28, %fd23, %fd23;
	add.f64 	%fd30, %fd119, 0dBFF0000000000000;
	mul.f64 	%fd31, %fd30, %fd29;
	fma.rn.f64 	%fd32, %fd30, %fd29, %fd31;
	mul.f64 	%fd33, %fd32, %fd32;
	mov.f64 	%fd34, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd35, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd36, %fd35, %fd33, %fd34;
	mov.f64 	%fd37, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd38, %fd36, %fd33, %fd37;
	mov.f64 	%fd39, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd40, %fd38, %fd33, %fd39;
	mov.f64 	%fd41, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd42, %fd40, %fd33, %fd41;
	mov.f64 	%fd43, 0d3F624924923BE72D;
	fma.rn.f64 	%fd44, %fd42, %fd33, %fd43;
	mov.f64 	%fd45, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd46, %fd44, %fd33, %fd45;
	mov.f64 	%fd47, 0d3FB5555555555554;
	fma.rn.f64 	%fd48, %fd46, %fd33, %fd47;
	sub.f64 	%fd49, %fd30, %fd32;
	add.f64 	%fd50, %fd49, %fd49;
	neg.f64 	%fd51, %fd32;
	fma.rn.f64 	%fd52, %fd51, %fd30, %fd50;
	mul.f64 	%fd53, %fd29, %fd52;
	mul.f64 	%fd54, %fd33, %fd48;
	fma.rn.f64 	%fd55, %fd54, %fd32, %fd53;
	xor.b32  	%r34, %r51, -2147483648;
	mov.u32 	%r35, 1127219200;
	mov.b64 	%fd56, {%r34, %r35};
	mov.u32 	%r36, -2147483648;
	mov.b64 	%fd57, {%r36, %r35};
	sub.f64 	%fd58, %fd56, %fd57;
	mov.f64 	%fd59, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd60, %fd58, %fd59, %fd32;
	neg.f64 	%fd61, %fd58;
	fma.rn.f64 	%fd62, %fd61, %fd59, %fd60;
	sub.f64 	%fd63, %fd62, %fd32;
	sub.f64 	%fd64, %fd55, %fd63;
	mov.f64 	%fd65, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd66, %fd58, %fd65, %fd64;
	add.f64 	%fd120, %fd60, %fd66;
	bra.uni 	BB0_11;

BB0_2:
	abs.f64 	%fd20, %fd1;
	setp.gtu.f64	%p5, %fd20, 0d7FF0000000000000;
	@%p5 bra 	BB0_5;
	bra.uni 	BB0_3;

BB0_5:
	add.f64 	%fd120, %fd1, %fd1;
	bra.uni 	BB0_11;

BB0_3:
	setp.eq.f64	%p6, %fd1, 0d0000000000000000;
	mov.f64 	%fd120, 0dFFF0000000000000;
	@%p6 bra 	BB0_11;

	setp.eq.f64	%p7, %fd1, 0d7FF0000000000000;
	selp.f64	%fd120, %fd1, 0dFFF8000000000000, %p7;

BB0_11:
	cvta.to.global.u64 	%rd9, %rd4;
	cvta.to.global.u64 	%rd2, %rd5;
	mul.ftz.f32 	%f3, %f2, 0f3F317218;
	mul.ftz.f32 	%f4, %f1, %f3;
	cvt.ftz.f64.f32	%fd67, %f4;
	fma.rn.f64 	%fd68, %fd1, %fd120, %fd67;
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.f32 	%f5, [%rd11];
	mul.ftz.f32 	%f6, %f1, %f5;
	cvt.ftz.f64.f32	%fd69, %f6;
	sub.f64 	%fd9, %fd68, %fd69;
	mul.ftz.f32 	%f7, %f5, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f8, %f7;
	cvt.ftz.f64.f32	%fd70, %f8;
	add.f64 	%fd10, %fd70, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd10;
	}
	setp.gt.f64	%p10, %fd10, 0d0000000000000000;
	setp.lt.s32	%p11, %r52, 2146435072;
	and.pred  	%p12, %p10, %p11;
	@%p12 bra 	BB0_16;
	bra.uni 	BB0_12;

BB0_16:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd10;
	}
	mov.u32 	%r54, -1023;
	setp.gt.s32	%p16, %r52, 1048575;
	@%p16 bra 	BB0_18;

	mul.f64 	%fd73, %fd10, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd73;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd73;
	}
	mov.u32 	%r54, -1077;

BB0_18:
	shr.u32 	%r39, %r52, 20;
	add.s32 	%r55, %r54, %r39;
	and.b32  	%r40, %r52, -2146435073;
	or.b32  	%r41, %r40, 1072693248;
	mov.b64 	%fd121, {%r53, %r41};
	setp.lt.s32	%p17, %r41, 1073127583;
	@%p17 bra 	BB0_20;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd121;
	}
	add.s32 	%r44, %r43, -1048576;
	mov.b64 	%fd121, {%r42, %r44};
	add.s32 	%r55, %r55, 1;

BB0_20:
	add.f64 	%fd75, %fd121, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd74,%fd75;
	// inline asm
	neg.f64 	%fd76, %fd75;
	fma.rn.f64 	%fd78, %fd76, %fd74, %fd19;
	fma.rn.f64 	%fd79, %fd78, %fd78, %fd78;
	fma.rn.f64 	%fd80, %fd79, %fd74, %fd74;
	add.f64 	%fd81, %fd121, 0dBFF0000000000000;
	mul.f64 	%fd82, %fd81, %fd80;
	fma.rn.f64 	%fd83, %fd81, %fd80, %fd82;
	mul.f64 	%fd84, %fd83, %fd83;
	mov.f64 	%fd85, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd86, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd87, %fd86, %fd84, %fd85;
	mov.f64 	%fd88, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd89, %fd87, %fd84, %fd88;
	mov.f64 	%fd90, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd91, %fd89, %fd84, %fd90;
	mov.f64 	%fd92, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd93, %fd91, %fd84, %fd92;
	mov.f64 	%fd94, 0d3F624924923BE72D;
	fma.rn.f64 	%fd95, %fd93, %fd84, %fd94;
	mov.f64 	%fd96, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd97, %fd95, %fd84, %fd96;
	mov.f64 	%fd98, 0d3FB5555555555554;
	fma.rn.f64 	%fd99, %fd97, %fd84, %fd98;
	sub.f64 	%fd100, %fd81, %fd83;
	add.f64 	%fd101, %fd100, %fd100;
	neg.f64 	%fd102, %fd83;
	fma.rn.f64 	%fd103, %fd102, %fd81, %fd101;
	mul.f64 	%fd104, %fd80, %fd103;
	mul.f64 	%fd105, %fd84, %fd99;
	fma.rn.f64 	%fd106, %fd105, %fd83, %fd104;
	xor.b32  	%r45, %r55, -2147483648;
	mov.u32 	%r46, 1127219200;
	mov.b64 	%fd107, {%r45, %r46};
	mov.u32 	%r47, -2147483648;
	mov.b64 	%fd108, {%r47, %r46};
	sub.f64 	%fd109, %fd107, %fd108;
	mov.f64 	%fd110, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd111, %fd109, %fd110, %fd83;
	neg.f64 	%fd112, %fd109;
	fma.rn.f64 	%fd113, %fd112, %fd110, %fd111;
	sub.f64 	%fd114, %fd113, %fd83;
	sub.f64 	%fd115, %fd106, %fd114;
	mov.f64 	%fd116, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd117, %fd109, %fd116, %fd115;
	add.f64 	%fd122, %fd111, %fd117;
	bra.uni 	BB0_21;

BB0_12:
	abs.f64 	%fd71, %fd10;
	setp.gtu.f64	%p13, %fd71, 0d7FF0000000000000;
	@%p13 bra 	BB0_15;
	bra.uni 	BB0_13;

BB0_15:
	add.f64 	%fd122, %fd10, %fd10;
	bra.uni 	BB0_21;

BB0_13:
	setp.eq.f64	%p14, %fd10, 0d0000000000000000;
	mov.f64 	%fd122, 0dFFF0000000000000;
	@%p14 bra 	BB0_21;

	setp.eq.f64	%p15, %fd10, 0d7FF0000000000000;
	selp.f64	%fd122, %fd10, 0dFFF8000000000000, %p15;

BB0_21:
	add.f64 	%fd118, %fd9, %fd122;
	cvt.rn.ftz.f32.f64	%f9, %fd118;
	add.s64 	%rd13, %rd2, %rd10;
	st.global.f32 	[%rd13], %f9;

BB0_22:
	ret;
}


